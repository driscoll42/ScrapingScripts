{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-01T19:37:30.217469Z",
     "start_time": "2024-09-01T19:37:29.480322Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from time import sleep\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from datetime import datetime\n",
    "import googlemaps\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlparse\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "import gc\n",
    "\n",
    "\n",
    "# TODO: Have good logic for retrying\n",
    "# TODO: Parallel?\n",
    "# TODO: If parallel, check if id exists, if so skip, but also need to make sure it's complete\n",
    "# TODO: Cache actual URL & state/country, update rather than full recreate\n",
    "# TODO: Have full list of categories cached\n",
    "# TODO: Show progress better"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "def get_country_state(url, library_name, verbose=False):\n",
    "    query_text = library_name\n",
    "    if url != 'None':\n",
    "        url = urlparse(url).netloc\n",
    "\n",
    "        region = url.split('.')[-1]\n",
    "        ignore_domains = ['com', 'gov', 'edu', 'net', 'org']\n",
    "        if any(x in region for x in ignore_domains):\n",
    "            region = ''\n",
    "    else:\n",
    "        region = ''\n",
    "\n",
    "    key = 'AIzaSyCwEWxZGoZiQoxwaQhrkJ2Wr17mB7CehZ0'  # Put your key here #\n",
    "    gmaps = googlemaps.Client(key=key)\n",
    "\n",
    "    # places_return = gmaps.find_place('ypl.gov.yk.ca', input_type='textquery')\n",
    "\n",
    "    places_return = gmaps.places(query_text, type='library', region=region)\n",
    "\n",
    "    try:\n",
    "        address = places_return['results'][0]['formatted_address']\n",
    "    except Exception as e:\n",
    "        return '', ''\n",
    "    reverse_geocode = gmaps.geocode(address)\n",
    "\n",
    "    address_components = reverse_geocode[0]['address_components']\n",
    "    country = ''\n",
    "    state = ''\n",
    "    for value in address_components:\n",
    "        long_name = value['long_name']\n",
    "        short_name = value['short_name']\n",
    "        types = value['types']\n",
    "        for type in types:\n",
    "            if 'country' in type:\n",
    "                country = short_name\n",
    "            elif 'administrative_area_level_1' in type:\n",
    "                state = short_name\n",
    "\n",
    "    return state, country\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-01T19:37:30.227016Z",
     "start_time": "2024-09-01T19:37:30.221475Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "cat_dict = {'Fiction ebooks'                   : 'EB-F',\n",
    "            'Nonfiction ebooks'                : 'EB-NF',\n",
    "            'Juvenile Fiction ebooks'          : 'EB-JF',\n",
    "            'Juvenile Nonfiction ebooks'       : 'EB-JNF',\n",
    "            'Young Adult Fiction ebooks'       : 'EB-YAF',\n",
    "            'Young Adult Nonfiction ebooks'    : 'EB-YANF',\n",
    "            'Fiction Audiobooks'               : 'AB-F',\n",
    "            'Nonfiction Audiobooks'            : 'AB-NF',\n",
    "            'Juvenile Fiction Audiobooks'      : 'AB-JF',\n",
    "            'Juvenile Nonfiction Audiobooks'   : 'AB-JNF',\n",
    "            'Young Adult Fiction Audiobooks'   : 'AB-YAF',\n",
    "            'Young Adult Nonfiction Audiobooks': 'AB-YANF',\n",
    "            'Magazines'                        : 'M',\n",
    "            'Videos'                           : 'V',\n",
    "            }\n",
    "eb_sub_list = ['EB-F-Fiction', 'EB-NF-Nonfiction', 'EB-YAF-Young Adult Fiction', 'EB-YANF-Young Adult Nonfiction',\n",
    "               'EB-JF-Juvenile Fiction', 'EB-JNF-Juvenile Nonfiction']\n",
    "ab_sub_list = ['AB-F-Fiction', 'AB-NF-Nonfiction', 'AB-YAF-Young Adult Fiction', 'AB-YANF-Young Adult Nonfiction',\n",
    "               'AB-JF-Juvenile Fiction', 'AB-JNF-Juvenile Nonfiction']\n",
    "\n",
    "\n",
    "def scrape_subjects(lib_dict, sleep_dur, verbose=False):\n",
    "    num_formats = len(driver.find_elements(By.XPATH, f'/html/body/div[2]/div[6]/div[2]/div/div/div[1]/div/a'))\n",
    "    if verbose: print('num_formats', num_formats)\n",
    "    sleep(sleep_dur)\n",
    "    for for_num in range(1, num_formats + 1):\n",
    "        sleep(sleep_dur)\n",
    "\n",
    "        format = driver.find_element(By.XPATH,\n",
    "                                     f'/html/body/div[2]/div[6]/div[2]/div/div/div[1]/div/a[{for_num}]/span')\n",
    "        format.click()\n",
    "        sleep(sleep_dur)\n",
    "\n",
    "        for_text = format.text\n",
    "        if verbose: print('for_text', for_text)\n",
    "\n",
    "        format_total = driver.find_element(By.XPATH, f'/html/body/div[2]/div[6]/div[3]/div/div/div/a').text\n",
    "        format_total = int(re.sub(\"[^0-9.]\", \"\", format_total))\n",
    "        lib_dict[f'{for_text} Total'] = format_total\n",
    "        if verbose: print('format_total', format_total)\n",
    "        if for_text == 'ALL FORMATS':\n",
    "            continue\n",
    "        if for_num == 1 and for_text != 'ALL FORMATS':\n",
    "            lib_dict['ALL FORMATS Total'] = format_total\n",
    "\n",
    "        num_categories = len(driver.find_elements(By.XPATH, '/html/body/div[2]/div[6]/div[4]/div/div/ul/li'))\n",
    "        if verbose: print('num_categories', num_categories)\n",
    "\n",
    "        cat_sum = 0\n",
    "        for cat_num in range(1, num_categories + 1):\n",
    "            sleep(sleep_dur)\n",
    "            category_full = driver.find_element(By.XPATH,\n",
    "                                                f'/html/body/div[2]/div[6]/div[4]/div/div/ul/li[{cat_num}]/div/div[1]/h2').text\n",
    "\n",
    "            if verbose: print('category_full', category_full)\n",
    "\n",
    "            category = cat_dict[category_full]\n",
    "\n",
    "            num_subjects = len(\n",
    "                    driver.find_elements(By.XPATH,\n",
    "                                         f'/html/body/div[2]/div[6]/div[4]/div/div/ul/li[{cat_num}]/div/div[2]/ul/li'))\n",
    "\n",
    "            for sub_num in range(1, num_subjects + 1):\n",
    "                cnt_str = driver.find_element(By.XPATH,\n",
    "                                              f'/html/body/div[2]/div[6]/div[4]/div/div/ul/li[{cat_num}]/div/div[2]/ul/li[{sub_num}]/div/div/a/div[1]/span').text\n",
    "                cnt = int(cnt_str.replace(',', ''))\n",
    "\n",
    "                subject = driver.find_element(By.XPATH,\n",
    "                                              f'/html/body/div[2]/div[6]/div[4]/div/div/ul/li[{cat_num}]/div/div[2]/ul/li[{sub_num}]/div/div/a/div[2]/span[1]').text\n",
    "                sub_label = driver.find_element(By.XPATH,\n",
    "                                                f'/html/body/div[2]/div[6]/div[4]/div/div/ul/li[{cat_num}]/div/div[2]/ul/li[{sub_num}]/div/div/a/div[2]/span[2]').text\n",
    "                lib_dict[f'{category}-{subject}{sub_label}'] = int(cnt)\n",
    "                if verbose: print(f'{category}-{subject}{sub_label}', lib_dict[f'{category}-{subject}{sub_label}'])\n",
    "                cat_sum += cnt\n",
    "                sleep(sleep_dur / 20.0)\n",
    "            category_full = category_full.replace(' ebooks', '').replace(' Audiobooks', '')\n",
    "            if f'{category}-{category_full}' not in lib_dict and category != 'M' and category != 'V':\n",
    "                raise Exception(f'Missing {category} category')\n",
    "\n",
    "        if cat_sum == 0:\n",
    "            raise Exception('Failed to parse categories')\n",
    "        if 'EB' in for_text:\n",
    "            tot_check = 0\n",
    "            for eb_sub in eb_sub_list:\n",
    "                tot_check += lib_dict.get(eb_sub, 0)\n",
    "            if format_total - tot_check < -100:\n",
    "                raise Exception('EB check failed')\n",
    "        if 'AUDIO' in for_text:\n",
    "            tot_check = 0\n",
    "            for ab_sub in ab_sub_list:\n",
    "                tot_check += lib_dict.get(ab_sub, 0)\n",
    "            if format_total - tot_check < -100:\n",
    "                raise Exception('AB check failed')\n",
    "\n",
    "    return lib_dict\n",
    "\n",
    "# new_dict = {'test': 0}\n",
    "# scrape_subjects(new_dict, 0.5, True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-01T19:37:36.755092Z",
     "start_time": "2024-09-01T19:37:36.742519Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "def catch_all_failure(websiteId, verbose=False):\n",
    "    found_site = False\n",
    "    library_dict = {'websiteId'      : websiteId,\n",
    "                    'Library OD URL' : '',\n",
    "                    'Library URL'    : '',\n",
    "                    'Library Name'   : '',\n",
    "                    'Status'         : '',\n",
    "                    'Scrape Datetime': datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")}\n",
    "    url = f'https://link.overdrive.com/?websiteId={websiteId}'\n",
    "    # https://greenville.libraryreserve.com/10/45/en/SignIn.htm?url=Default.htm\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        found_site = True\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        library_dict['Status'] = 'Error'\n",
    "    if found_site:\n",
    "        curr_url = driver.current_url\n",
    "        library_dict['Status'] = 'New Type of Site'\n",
    "        library_dict['Library URL'] = curr_url\n",
    "    return library_dict\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-01T19:37:38.279569Z",
     "start_time": "2024-09-01T19:37:38.275531Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "def get_library_data(websiteId, sleep_dur=0.0, get_subjects=True, verbose=False):\n",
    "    found_site = False\n",
    "    library_dict = {'websiteId'      : websiteId,\n",
    "                    'Library OD URL' : '',\n",
    "                    'Library URL'    : '',\n",
    "                    'Library Name'   : '',\n",
    "                    'Status'         : '',\n",
    "                    'Scrape Datetime': datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")}\n",
    "    url = f'https://link.overdrive.com/?websiteId={websiteId}'\n",
    "    # https://greenville.libraryreserve.com/10/45/en/SignIn.htm?url=Default.htm\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        found_site = True\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        library_dict['Status'] = 'Error'\n",
    "    if found_site:\n",
    "\n",
    "        curr_url = driver.current_url\n",
    "        if curr_url == \"https://www.overdrive.com/\":\n",
    "            library_dict['Library OD URL'] = curr_url\n",
    "            library_dict['Status'] = 'N/A'\n",
    "            print(websiteId, curr_url)\n",
    "            return library_dict\n",
    "\n",
    "        sleep(sleep_dur)\n",
    "        curr_url = driver.current_url\n",
    "        print(websiteId, curr_url)\n",
    "        library_dict['Library OD URL'] = curr_url\n",
    "\n",
    "        if curr_url == \"https://www.overdrive.com/\":\n",
    "            library_dict['Status'] = 'N/A'\n",
    "        elif \"merged\" in curr_url:\n",
    "            # https://laman.overdrive.com/merged\n",
    "            title = driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[1]/div/a')\n",
    "            library_name = title.get_attribute(\"aria-label\")\n",
    "            print(library_name, 'MERGED')\n",
    "            library_dict['Library Name'] = library_name\n",
    "            library_dict['Status'] = 'Merged'\n",
    "\n",
    "        elif \"terminated\" in curr_url:\n",
    "            title = driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[1]/div/a')\n",
    "            library_name = title.get_attribute(\"aria-label\")\n",
    "            print(library_name, 'TERMINATED')\n",
    "            library_dict['Library Name'] = library_name\n",
    "            library_dict['Status'] = 'Terminated'\n",
    "\n",
    "        elif \"siteclosed\" in curr_url:\n",
    "            library_dict['Status'] = 'Closed'\n",
    "        elif \"classlink.com\" in curr_url:\n",
    "            library_dict['Status'] = 'Classlink, likely Sora'\n",
    "        elif \"accounts.google.com\" in curr_url:\n",
    "            redirect_url = driver.execute_script('return window.document.referrer')\n",
    "            library_dict['Status'] = 'Google Redirect, likely Sora'\n",
    "            library_dict['Library URL'] = redirect_url\n",
    "\n",
    "        elif \"soraapp\" in curr_url:\n",
    "            redirect_url = driver.execute_script('return window.document.referrer')\n",
    "            library_dict['Status'] = 'Sora Library'\n",
    "            library_dict['Library URL'] = redirect_url\n",
    "            try:\n",
    "                school_name = driver.find_element(By.XPATH,\n",
    "                                                  \"/html/body/div[7]/div[1]/section[5]/div[3]/div[3]/div/div[2]/div/div[1]/div/h1\").text\n",
    "                library_dict['Library Name'] = school_name\n",
    "                print(school_name, 'sora')\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        elif \"lexisnexis\" in curr_url or \"lexisdl.com\" in curr_url:\n",
    "            redirect_url = driver.execute_script('return window.document.referrer')\n",
    "            library_dict['Status'] = 'LexisNexis'\n",
    "            library_dict['Library URL'] = redirect_url\n",
    "        elif \"microsoftonline\" in curr_url:\n",
    "            redirect_url = driver.execute_script('return window.document.referrer')\n",
    "            library_dict['Status'] = 'Microsoft Login'\n",
    "            library_dict['Library URL'] = redirect_url\n",
    "        elif \"rapididentity\" in curr_url:\n",
    "            redirect_url = driver.execute_script('return window.document.referrer')\n",
    "            library_dict['Status'] = 'RapidIdentity Login'\n",
    "            library_dict['Library URL'] = redirect_url\n",
    "        elif \"cmcss.net\" in curr_url:\n",
    "            redirect_url = driver.execute_script('return window.document.referrer')\n",
    "            library_dict['Status'] = 'CMCSS Login'\n",
    "            library_dict['Library URL'] = redirect_url\n",
    "        elif \"libraryreserve\" in curr_url or \"follettsoftware\" in curr_url:\n",
    "            # 217 https://adobelibrary.libraryreserve.com/\n",
    "            redirect_url = driver.execute_script('return window.document.referrer')\n",
    "            # 105\n",
    "            library_dict['Status'] = 'Other Redirect'\n",
    "            library_dict['Library URL'] = redirect_url\n",
    "            # https://starkville.libraryreserve.com/10/50/en/Default.htm\n",
    "        elif \"demo.lib\" in curr_url or \"demo.overdrive\" in curr_url or \"odnonprofit\" in curr_url:\n",
    "            # 561 http://koreandemo.lib.overdrive.com/\n",
    "            library_dict['Status'] = 'Demo Site'\n",
    "        else:\n",
    "            try:\n",
    "                uae = driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div/div/div/h1')\n",
    "                if uae.text == 'Unexpected Application Error':\n",
    "                    library_dict['Status'] = 'Unexpected Application Error'\n",
    "                    library_dict['Library URL'] = curr_url\n",
    "                    return library_dict\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "            sleep(sleep_dur)\n",
    "            webdriver.ActionChains(driver).send_keys(Keys.ESCAPE).perform()\n",
    "            sleep(sleep_dur)\n",
    "            library_dict['Status'] = 'Active'\n",
    "\n",
    "            title = driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[1]/nav/section/div[2]/a')\n",
    "            library_name = title.get_attribute(\"aria-label\").split(\":\")[0]\n",
    "            print(library_name)\n",
    "            library_dict['Library Name'] = library_name\n",
    "            lib_url_found = False\n",
    "            try:\n",
    "                library_url = driver.find_element(By.XPATH,\n",
    "                                                  '/html/body/div[3]/div[1]/footer/div/div[1]/div/div[3]/a[1]')\n",
    "                lib_url_found = True\n",
    "            except Exception as e:\n",
    "                try:\n",
    "                    library_url = driver.find_element(By.XPATH,\n",
    "                                                      '/html/body/div[3]/div[2]/footer/div/div[1]/div/div[3]/a[1]')\n",
    "                    lib_url_found = True\n",
    "                except Exception as e:\n",
    "                    library_url = ''\n",
    "            if lib_url_found:\n",
    "                library_url = library_url.get_attribute(\"href\")\n",
    "                print('library_url', library_url)\n",
    "            library_dict['Library URL'] = library_url\n",
    "\n",
    "            if get_subjects:\n",
    "                sleep(sleep_dur)\n",
    "                webdriver.ActionChains(driver).send_keys(Keys.ESCAPE).perform()\n",
    "                sleep(sleep_dur)\n",
    "                driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[1]/nav/section/ul[1]/li[1]/a').click()\n",
    "\n",
    "                sleep(sleep_dur)\n",
    "\n",
    "                '''if 1 == 0:\n",
    "                    state, country = get_country_state(library_dict['Library URL'], library_dict['Library Name'])\n",
    "                    library_dict['State'] = state\n",
    "                    library_dict['Country'] = country'''\n",
    "\n",
    "                scrape_subjects(library_dict, sleep_dur, verbose)\n",
    "\n",
    "    return library_dict\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-01T19:37:42.106804Z",
     "start_time": "2024-09-01T19:37:42.095210Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T19:37:44.550729Z",
     "start_time": "2024-09-01T19:37:44.543620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_valid_ids():\n",
    "    # Find valid websiteids\n",
    "\n",
    "    # make a string of the current date in 2020201 format\n",
    "    date = datetime.now().strftime(\"%Y%m%d\")\n",
    "    filename = f'valid_id_scrape_{date}.csv'\n",
    "    verbose = False\n",
    "    driver = webdriver.Firefox()\n",
    "\n",
    "    try:\n",
    "        overdrive_df = pd.read_csv(filename)\n",
    "    except Exception as e:\n",
    "        overdrive_df = pd.DataFrame()\n",
    "\n",
    "    sleep(1)\n",
    "\n",
    "    for x in range(0, 50):\n",
    "        last_good = x * 10000\n",
    "        for websiteId_seq in range(0, 10000):\n",
    "            websiteId = int(x * 10000 + websiteId_seq)\n",
    "            print(websiteId, last_good, websiteId - last_good)\n",
    "\n",
    "            state, country = '', ''\n",
    "            num_tries = 4\n",
    "\n",
    "            for attempts in range(1, num_tries):\n",
    "                library_dict = {}\n",
    "                print('attempt', attempts)\n",
    "                try:\n",
    "                    library_dict = get_library_data(websiteId, 0.5 * (2 ** attempts), get_subjects=False, verbose=False)\n",
    "                except Exception as e:\n",
    "                    print('Exception', e)\n",
    "                else:\n",
    "                    break\n",
    "                finally:\n",
    "                    if attempts >= num_tries - 1:\n",
    "                        library_dict = catch_all_failure(websiteId, verbose)\n",
    "\n",
    "            # Add the library_dict to the dataframe using concat isntead of append\n",
    "            overdrive_df = pd.concat([overdrive_df, pd.DataFrame([library_dict])], ignore_index=True)\n",
    "            overdrive_df.to_csv(filename)\n",
    "\n",
    "            if library_dict['Library OD URL'] != \"https://www.overdrive.com/\" and 'overdrive.com' in library_dict[\n",
    "                'Library OD URL']:\n",
    "                last_good = websiteId\n",
    "\n",
    "            if x % 5 == 0:\n",
    "                overdrive_df.to_csv(f'backup_{filename}.csv')\n",
    "            if websiteId - last_good > 250:\n",
    "                print(f'Skipping to next x. Curr x: {x} - Last Good: {last_good} - Last Attempted: {websiteId}')\n",
    "                break\n",
    "        overdrive_df.to_csv(f'backup_{filename}.csv')\n",
    "    return overdrive_df"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T19:38:07.295163Z",
     "start_time": "2024-09-01T19:38:07.288326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_library_details(valid_ids, overdrive_df, safe_save=True):\n",
    "    for idx, row in valid_ids.iterrows():\n",
    "        websiteId = row['websiteId']\n",
    "\n",
    "        if row['Status'] != 'Active':\n",
    "            continue\n",
    "\n",
    "        state, country = '', ''\n",
    "        num_tries = 6\n",
    "\n",
    "        for attempts in range(1, num_tries):\n",
    "            library_dict = {}\n",
    "            if attempts > 1:\n",
    "                print('attempt', attempts)\n",
    "            try:\n",
    "                library_dict = get_library_data(websiteId, 0.125 * (2 ** attempts) + 0.0025, get_subjects=True,\n",
    "                                                verbose=False)\n",
    "                if library_dict['ALL FORMATS Total'] == 0:\n",
    "                    raise Exception('No items found')\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            else:\n",
    "                break\n",
    "            finally:\n",
    "                if attempts >= num_tries - 1:\n",
    "                    library_dict = catch_all_failure(websiteId, verbose)\n",
    "\n",
    "        overdrive_df = pd.concat([overdrive_df, pd.DataFrame([library_dict])], ignore_index=True)\n",
    "        \n",
    "        if safe_save:\n",
    "            overdrive_df.to_csv(f'{filename}.csv')\n",
    "        elif idx % 10 == 0:\n",
    "            overdrive_df.to_csv(f'{filename}.csv')\n",
    "            \n",
    "        # Find that the memory gets cluttered after a while, good to just purge every so often\n",
    "        if idx % 50 == 0:\n",
    "            driver.delete_all_cookies()  # Clear cookies\n",
    "            driver.execute_script(\"window.localStorage.clear();\")  # Clear local storage\n",
    "            driver.execute_script(\"window.sessionStorage.clear();\")  # Clear session storage\n",
    "            gc.collect()\n",
    "            \n",
    "    overdrive_df.to_csv(f'{filename}_with_data.csv')\n",
    "    return overdrive_df"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T19:38:07.594444Z",
     "start_time": "2024-09-01T19:38:07.588921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def organizeData(overdrive_df, filename):\n",
    "    df = overdrive_df[sorted(overdrive_df.columns)]\n",
    "    priority_columns = ['websiteId', 'Library Name', 'Library OD URL', 'Library URL', 'Status',\n",
    "                        #'State', 'Country',\n",
    "                        'ALL FORMATS Total', 'EBOOKS Total', 'AUDIOBOOKS Total', 'MAGAZINES Total', 'VIDEOS Total',\n",
    "                        'EB-F-Fiction',\n",
    "                        'EB-NF-Nonfiction', 'EB-YAF-Young Adult Fiction', 'EB-YANF-Young Adult Nonfiction',\n",
    "                        'EB-JF-Juvenile Fiction', 'EB-JNF-Juvenile Nonfiction', 'AB-F-Fiction', 'AB-NF-Nonfiction',\n",
    "                        'AB-YAF-Young Adult Fiction', 'AB-YANF-Young Adult Nonfiction', 'AB-JF-Juvenile Fiction',\n",
    "                        'AB-JNF-Juvenile Nonfiction', 'Scrape Datetime']\n",
    "\n",
    "    for pc in reversed(priority_columns):\n",
    "        # check if column exists\n",
    "        if pc not in df.columns:\n",
    "            continue\n",
    "        df_temp = df.pop(pc)\n",
    "        df = pd.concat([df_temp, df], axis=1)\n",
    "    df.to_csv(f'sorted_{filename}.csv')\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T19:35:20.352288Z",
     "start_time": "2024-09-01T19:35:20.347688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO: Document how to use this\n",
    "def getLocationData():\n",
    "    filename = 'unknownstate.csv'\n",
    "    loc_df = pd.read_csv(filename)\n",
    "    \n",
    "    for idx, row in loc_df.iterrows():\n",
    "        sleep(0.5)\n",
    "        websiteId = row['websiteId']\n",
    "        lib_url = row['Library URL']\n",
    "        lib_name = row['Library Name']\n",
    "        state, country = get_country_state(lib_url, lib_name)\n",
    "        print(lib_name, state, country)\n",
    "        loc_df.at[idx, 'state'] = state\n",
    "        loc_df.at[idx, 'country'] = country\n",
    "    \n",
    "        if idx % 5 == 0:\n",
    "            loc_df.to_csv(f'backup_{filename}')\n",
    "    \n",
    "    loc_df.to_csv(f'complete_{filename}')\n"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "filename = '221229'\n",
    "activeIds = f'{filename}_scrape.csv'\n",
    "verbose = False\n",
    "\n",
    "getValidIds = False\n",
    "getLibraryData = True\n",
    "orgData = True\n",
    "id_restart_from = 360590\n",
    "headless_scraping = True # Not encouraged if testing this script out\n",
    "\n",
    "try:\n",
    "    overdrive_df = pd.read_csv(filename)\n",
    "except Exception as e:\n",
    "    overdrive_df = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    valid_ids = pd.read_csv(activeIds)\n",
    "except Exception as e:\n",
    "    valid_ids = pd.DataFrame()\n",
    "\n",
    "options = Options()\n",
    "if headless_scraping:\n",
    "    options.add_argument(\"--headless\")\n",
    "    \n",
    "driver = webdriver.Firefox(options=options)\n",
    "\n",
    "\n",
    "if getValidIds:\n",
    "    overdrive_df = get_valid_ids()\n",
    "if getLibraryData:\n",
    "    overdrive_df = get_library_details(valid_ids, overdrive_df, id_restart_from)\n",
    "if orgData:\n",
    "    overdrive_df = organizeData(overdrive_df, filename)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-01T19:37:28.111186600Z",
     "start_time": "2024-09-01T19:35:22.366252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 https://clevnet.overdrive.com/\n",
      "CLEVNET\n",
      "12 https://kcls.overdrive.com/\n",
      "King County Library System\n",
      "15 https://youngstown.overdrive.com/\n",
      "The Public Library of Youngstown and Mahoning County\n",
      "'ALL FORMATS Total'\n",
      "attempt 2\n",
      "15 https://youngstown.overdrive.com/\n",
      "The Public Library of Youngstown and Mahoning County\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": "",
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
