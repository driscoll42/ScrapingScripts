{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from time import sleep\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from datetime import datetime\n",
    "import googlemaps\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "pd.set_option('max_columns', None)\n",
    "\n",
    "\n",
    "# TODO: Have good logic for retrying\n",
    "# TODO: Parallel?\n",
    "# TODO: If parallel, check if id exists, if so skip, but also need to make sure it's complete\n",
    "# TODO: 751 stuck on constant refresh\n",
    "# TODO: Cache actual URL & state/country, update rather than full recreate\n",
    "# TODO: Have full list of categories cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_country_state(url, library_name, verbose=False):\n",
    "    url = urlparse(url).netloc\n",
    "\n",
    "    query_text = library_name\n",
    "\n",
    "    region = url.split('.')[-1]\n",
    "    ignore_domains = ['com', 'gov', 'edu', 'net', 'org']\n",
    "    if any(x in region for x in ignore_domains):\n",
    "        region = ''\n",
    "\n",
    "    key = '' # Put your key here\n",
    "    gmaps = googlemaps.Client(key=key)\n",
    "\n",
    "    # places_return = gmaps.find_place('ypl.gov.yk.ca', input_type='textquery')\n",
    "\n",
    "    places_return = gmaps.places(query_text, type='library', region=region)\n",
    "\n",
    "    try:\n",
    "        address = places_return['results'][0]['formatted_address']\n",
    "    except Exception as e:\n",
    "        return '', ''\n",
    "    reverse_geocode = gmaps.geocode(address)\n",
    "\n",
    "    address_components = reverse_geocode[0]['address_components']\n",
    "    country = ''\n",
    "    state = ''\n",
    "    for value in address_components:\n",
    "        long_name = value['long_name']\n",
    "        short_name = value['short_name']\n",
    "        types = value['types']\n",
    "        for type in types:\n",
    "            if 'country' in type:\n",
    "                country = short_name\n",
    "            elif 'administrative_area_level_1' in type:\n",
    "                state = short_name\n",
    "\n",
    "    return state, country\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "cat_dict = {'Fiction ebooks'                   : 'EB-F',\n",
    "            'Nonfiction ebooks'                : 'EB-NF',\n",
    "            'Juvenile Fiction ebooks'          : 'EB-JF',\n",
    "            'Juvenile Nonfiction ebooks'       : 'EB-JNF',\n",
    "            'Young Adult Fiction ebooks'       : 'EB-YAF',\n",
    "            'Young Adult Nonfiction ebooks'    : 'EB-YANF',\n",
    "            'Fiction Audiobooks'               : 'AB-F',\n",
    "            'Nonfiction Audiobooks'            : 'AB-NF',\n",
    "            'Juvenile Fiction Audiobooks'      : 'AB-JF',\n",
    "            'Juvenile Nonfiction Audiobooks'   : 'AB-JNF',\n",
    "            'Young Adult Fiction Audiobooks'   : 'AB-YAF',\n",
    "            'Young Adult Nonfiction Audiobooks': 'AB-YANF',\n",
    "            'Magazines'                        : 'M',\n",
    "            'Videos'                           : 'V',\n",
    "            }\n",
    "eb_sub_list = ['EB-F-Fiction', 'EB-NF-Nonfiction', 'EB-YAF-Young Adult Fiction', 'EB-YANF-Young Adult Nonfiction',\n",
    "               'EB-JF-Juvenile Fiction', 'EB-JNF-Juvenile Nonfiction']\n",
    "ab_sub_list = ['AB-F-Fiction', 'AB-NF-Nonfiction', 'AB-YAF-Young Adult Fiction', 'AB-YANF-Young Adult Nonfiction',\n",
    "               'AB-JF-Juvenile Fiction', 'AB-JNF-Juvenile Nonfiction']\n",
    "\n",
    "\n",
    "def scrape_subjects(lib_dict, sleep_dur, verbose=False):\n",
    "    num_formats = len(driver.find_elements(By.XPATH, f'/html/body/div[2]/div[5]/div[2]/div/div/div[1]/div/a'))\n",
    "    sleep(sleep_dur)\n",
    "    for for_num in range(1, num_formats + 1):\n",
    "\n",
    "        format = driver.find_element(By.XPATH,\n",
    "                                     f'/html/body/div[2]/div[5]/div[2]/div/div/div[1]/div/a[{for_num}]/span')\n",
    "        format.click()\n",
    "        sleep(sleep_dur)\n",
    "\n",
    "        for_text = format.text\n",
    "\n",
    "        format_total = driver.find_element(By.XPATH, f'/html/body/div[2]/div[5]/div[3]/div/div/div/a').text\n",
    "        format_total = int(re.sub(\"[^0-9.]\", \"\", format_total))\n",
    "        lib_dict[f'{for_text} Total'] = format_total\n",
    "        if for_text == 'ALL FORMATS':\n",
    "            continue\n",
    "        if for_num == 1 and for_text != 'ALL FORMATS':\n",
    "            lib_dict['ALL FORMATS Total'] = format_total\n",
    "\n",
    "        num_categories = len(driver.find_elements(By.XPATH, '/html/body/div[2]/div[5]/div[4]/div/div/ul/li'))\n",
    "        cat_sum = 0\n",
    "        for cat_num in range(1, num_categories + 1):\n",
    "            category_full = driver.find_element(By.XPATH,\n",
    "                                           f'/html/body/div[2]/div[5]/div[4]/div/div/ul/li[{cat_num}]/div/div[1]/h2').text\n",
    "\n",
    "            category = cat_dict[category_full]\n",
    "\n",
    "            num_subjects = len(\n",
    "                    driver.find_elements(By.XPATH,\n",
    "                                         f'/html/body/div[2]/div[5]/div[4]/div/div/ul/li[{cat_num}]/div/div[2]/ul/li'))\n",
    "\n",
    "            for sub_num in range(1, num_subjects + 1):\n",
    "                cnt_str = driver.find_element(By.XPATH,\n",
    "                                              f'/html/body/div[2]/div[5]/div[4]/div/div/ul/li[{cat_num}]/div/div[2]/ul/li[{sub_num}]/div/div/a/div[1]/span').text\n",
    "                cnt = int(cnt_str.replace(',', ''))\n",
    "\n",
    "                subject = driver.find_element(By.XPATH,\n",
    "                                              f'/html/body/div[2]/div[5]/div[4]/div/div/ul/li[{cat_num}]/div/div[2]/ul/li[{sub_num}]/div/div/a/div[2]/span[1]').text\n",
    "                sub_label = driver.find_element(By.XPATH,\n",
    "                                                f'/html/body/div[2]/div[5]/div[4]/div/div/ul/li[{cat_num}]/div/div[2]/ul/li[{sub_num}]/div/div/a/div[2]/span[2]').text\n",
    "                lib_dict[f'{category}-{subject}{sub_label}'] = int(cnt)\n",
    "                if verbose: print(f'{category}-{subject}{sub_label}', lib_dict[f'{category}-{subject}{sub_label}'])\n",
    "                cat_sum += cnt\n",
    "            category_full = category_full.replace(' ebooks', '').replace(' Audiobooks', '')\n",
    "            if f'{category}-{category_full}' not in lib_dict and category != 'M' and category != 'V':\n",
    "                raise Exception(f'Missing {category} category')\n",
    "\n",
    "        if cat_sum == 0:\n",
    "            raise Exception('Failed to parse categories')\n",
    "        if 'EB' in for_text:\n",
    "            tot_check = 0\n",
    "            for eb_sub in eb_sub_list:\n",
    "                tot_check += lib_dict.get(eb_sub, 0)\n",
    "            if format_total - tot_check < -100:\n",
    "                raise Exception('EB check failed')\n",
    "        if 'AUDIO' in for_text:\n",
    "            tot_check = 0\n",
    "            for ab_sub in ab_sub_list:\n",
    "                tot_check += lib_dict.get(ab_sub, 0)\n",
    "            if format_total - tot_check < -100:\n",
    "                raise Exception('AB check failed')\n",
    "\n",
    "    return lib_dict\n",
    "\n",
    "# new_dict = {'test': 0}\n",
    "# scrape_subjects(new_dict, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def catch_all_failure(websiteId, verbose=False):\n",
    "    found_site = False\n",
    "    library_dict = {'websiteId'      : websiteId,\n",
    "                    'Library OD URL' : '',\n",
    "                    'Library URL'    : '',\n",
    "                    'Library Name'   : '',\n",
    "                    'Status'         : '',\n",
    "                    'Scrape Datetime': datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")}\n",
    "    url = f'https://link.overdrive.com/?websiteId={websiteId}'\n",
    "    # https://greenville.libraryreserve.com/10/45/en/SignIn.htm?url=Default.htm\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        found_site = True\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        library_dict['Status'] = 'Error'\n",
    "    if found_site:\n",
    "        curr_url = driver.current_url\n",
    "        library_dict['Status'] = 'New Type of Site'\n",
    "        library_dict['Library URL'] = curr_url\n",
    "    return library_dict\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_library_data(websiteId, sleep_dur=0.0, verbose=False):\n",
    "    found_site = False\n",
    "    library_dict = {'websiteId'      : websiteId,\n",
    "                    'Library OD URL' : '',\n",
    "                    'Library URL'    : '',\n",
    "                    'Library Name'   : '',\n",
    "                    'Status'         : '',\n",
    "                    'Scrape Datetime': datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")}\n",
    "    url = f'https://link.overdrive.com/?websiteId={websiteId}'\n",
    "    # https://greenville.libraryreserve.com/10/45/en/SignIn.htm?url=Default.htm\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        found_site = True\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        library_dict['Status'] = 'Error'\n",
    "    if found_site:\n",
    "\n",
    "        curr_url = driver.current_url\n",
    "        if curr_url == \"https://www.overdrive.com/\":\n",
    "            library_dict['Library OD URL'] = curr_url\n",
    "            library_dict['Status'] = 'N/A'\n",
    "            print(websiteId, curr_url)\n",
    "            return library_dict\n",
    "\n",
    "        sleep(sleep_dur)\n",
    "        curr_url = driver.current_url\n",
    "        print(websiteId, curr_url)\n",
    "        library_dict['Library OD URL'] = curr_url\n",
    "\n",
    "        if curr_url == \"https://www.overdrive.com/\":\n",
    "            library_dict['Status'] = 'N/A'\n",
    "        elif \"merged\" in curr_url:\n",
    "            # https://laman.overdrive.com/merged\n",
    "            title = driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[1]/div/a')\n",
    "            library_name = title.get_attribute(\"aria-label\")\n",
    "            print(library_name, 'MERGED')\n",
    "            library_dict['Library Name'] = library_name\n",
    "            library_dict['Status'] = 'Merged'\n",
    "\n",
    "        elif \"terminated\" in curr_url:\n",
    "            title = driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[1]/div/a')\n",
    "            library_name = title.get_attribute(\"aria-label\")\n",
    "            print(library_name, 'TERMINATED')\n",
    "            library_dict['Library Name'] = library_name\n",
    "            library_dict['Status'] = 'Terminated'\n",
    "\n",
    "        elif \"siteclosed\" in curr_url:\n",
    "            library_dict['Status'] = 'Closed'\n",
    "        elif \"classlink.com\" in curr_url:\n",
    "            library_dict['Status'] = 'Classlink, likely Sora'\n",
    "        elif \"accounts.google.com\" in curr_url:\n",
    "            redirect_url = driver.execute_script('return window.document.referrer')\n",
    "            library_dict['Status'] = 'Google Redirect, likely Sora'\n",
    "            library_dict['Library URL'] = redirect_url\n",
    "\n",
    "        elif \"soraapp\" in curr_url:\n",
    "            redirect_url = driver.execute_script('return window.document.referrer')\n",
    "            library_dict['Status'] = 'Sora Library'\n",
    "            library_dict['Library URL'] = redirect_url\n",
    "            try:\n",
    "                school_name = driver.find_element(By.XPATH,\n",
    "                                                  \"/html/body/div[7]/div[1]/section[5]/div[3]/div[3]/div/div[2]/div/div[1]/div/h1\").text\n",
    "                library_dict['Library Name'] = school_name\n",
    "                print(school_name)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        elif \"lexisnexis\" in curr_url or \"lexisdl.com\" in curr_url:\n",
    "            redirect_url = driver.execute_script('return window.document.referrer')\n",
    "            library_dict['Status'] = 'LexisNexis'\n",
    "            library_dict['Library URL'] = redirect_url\n",
    "        elif \"microsoftonline\" in curr_url:\n",
    "            redirect_url = driver.execute_script('return window.document.referrer')\n",
    "            library_dict['Status'] = 'Microsoft Login'\n",
    "            library_dict['Library URL'] = redirect_url\n",
    "        elif \"rapididentity\" in curr_url:\n",
    "            redirect_url = driver.execute_script('return window.document.referrer')\n",
    "            library_dict['Status'] = 'RapidIdentity Login'\n",
    "            library_dict['Library URL'] = redirect_url\n",
    "        elif \"cmcss.net\" in curr_url:\n",
    "            redirect_url = driver.execute_script('return window.document.referrer')\n",
    "            library_dict['Status'] = 'CMCSS Login'\n",
    "            library_dict['Library URL'] = redirect_url\n",
    "        elif \"libraryreserve\" in curr_url or \"follettsoftware\" in curr_url:\n",
    "            # 217 https://adobelibrary.libraryreserve.com/\n",
    "            redirect_url = driver.execute_script('return window.document.referrer')\n",
    "            # 105\n",
    "            library_dict['Status'] = 'Other Redirect'\n",
    "            library_dict['Library URL'] = redirect_url\n",
    "            # https://starkville.libraryreserve.com/10/50/en/Default.htm\n",
    "        elif \"demo.lib\" in curr_url or \"demo.overdrive\" in curr_url or \"odnonprofit\" in curr_url:\n",
    "            # 561 http://koreandemo.lib.overdrive.com/\n",
    "            library_dict['Status'] = 'Demo Site'\n",
    "        else:\n",
    "            sleep(sleep_dur)\n",
    "            webdriver.ActionChains(driver).send_keys(Keys.ESCAPE).perform()\n",
    "            sleep(sleep_dur)\n",
    "            library_dict['Status'] = 'Active'\n",
    "\n",
    "            title = driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[1]/nav/section/div[2]/a')\n",
    "            library_name = title.get_attribute(\"aria-label\").split(\":\")[0]\n",
    "            print(library_name)\n",
    "            library_dict['Library Name'] = library_name\n",
    "            lib_url_found = False\n",
    "            try:\n",
    "                library_url = driver.find_element(By.XPATH,\n",
    "                                                  '/html/body/div[3]/div[1]/footer/div/div[1]/div/div[3]/a[1]')\n",
    "                lib_url_found = True\n",
    "            except Exception as e:\n",
    "                try:\n",
    "                    library_url = driver.find_element(By.XPATH,\n",
    "                                                      '/html/body/div[3]/div[2]/footer/div/div[1]/div/div[3]/a[1]')\n",
    "                    lib_url_found = True\n",
    "                except Exception as e:\n",
    "                    library_url = ''\n",
    "            if lib_url_found:\n",
    "                library_url = library_url.get_attribute(\"href\")\n",
    "            print(library_url)\n",
    "            library_dict['Library URL'] = library_url\n",
    "            sleep(sleep_dur)\n",
    "            webdriver.ActionChains(driver).send_keys(Keys.ESCAPE).perform()\n",
    "            sleep(sleep_dur)\n",
    "\n",
    "            driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[1]/nav/section/ul[1]/li[1]/a').click()\n",
    "\n",
    "            sleep(sleep_dur)\n",
    "\n",
    "            '''if 1 == 0:\n",
    "                state, country = get_country_state(library_dict['Library URL'], library_dict['Library Name'])\n",
    "                library_dict['State'] = state\n",
    "                library_dict['Country'] = country'''\n",
    "\n",
    "            scrape_subjects(library_dict, sleep_dur, verbose)\n",
    "\n",
    "    return library_dict\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "filename = 'ODRetry_11.csv'\n",
    "activeIds = 'ValidWebsiteIds_2.csv'\n",
    "verbose = False\n",
    "try:\n",
    "    overdrive_df = pd.read_csv(filename)\n",
    "except Exception as e:\n",
    "    overdrive_df = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    valid_ids = pd.read_csv(activeIds)\n",
    "except Exception as e:\n",
    "    valid_ids = pd.DataFrame()\n",
    "\n",
    "driver = webdriver.Firefox()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for idx, row in valid_ids.iterrows():\n",
    "    websiteId = row['websiteId']\n",
    "    state, country = '', ''\n",
    "    num_tries = 8\n",
    "\n",
    "    for attempts in range(num_tries):\n",
    "        library_dict = {}\n",
    "        print(attempts)\n",
    "        try:\n",
    "            library_dict = get_library_data(websiteId, 0.5 * (2 ** attempts), verbose)\n",
    "            if library_dict['ALL FORMATS Total'] == 0:\n",
    "                raise Exception('No items found')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        else:\n",
    "            break\n",
    "        finally:\n",
    "            if attempts >= num_tries - 1:\n",
    "                library_dict = catch_all_failure(websiteId, verbose)\n",
    "\n",
    "    overdrive_df = overdrive_df.append(library_dict, ignore_index=True)\n",
    "    overdrive_df.to_csv(filename)\n",
    "\n",
    "    if library_dict['Library OD URL'] != \"https://www.overdrive.com/\":\n",
    "        last_good = websiteId\n",
    "\n",
    "    if idx % 5 == 0:\n",
    "        overdrive_df.to_csv(f'backup_{filename}')\n",
    "overdrive_df.to_csv(f'backup_{filename}')\n",
    "driver.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "df = overdrive_df[sorted(overdrive_df.columns)]\n",
    "\n",
    "priority_columns = ['websiteId', 'Library Name', 'Library OD URL', 'Library URL', 'Status',\n",
    "                    #'State', 'Country',\n",
    "                    'ALL FORMATS Total', 'EBOOKS Total', 'AUDIOBOOKS Total', 'MAGAZINES Total', 'VIDEOS Total',\n",
    "                    'EB-F-Fiction',\n",
    "                    'EB-NF-Nonfiction', 'EB-YAF-Young Adult Fiction', 'EB-YANF-Young Adult Nonfiction',\n",
    "                    'EB-JF-Juvenile Fiction', 'EB-JNF-Juvenile Nonfiction', 'AB-F-Fiction', 'AB-NF-Nonfiction',\n",
    "                    'AB-YAF-Young Adult Fiction', 'AB-YANF-Young Adult Nonfiction', 'AB-JF-Juvenile Fiction',\n",
    "                    'AB-JNF-Juvenile Nonfiction', 'Scrape Datetime']\n",
    "\n",
    "for pc in reversed(priority_columns):\n",
    "    df_temp = df.pop(pc)\n",
    "    df = pd.concat([df_temp, df], axis=1)\n",
    "df.to_csv(f'test_{filename}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}